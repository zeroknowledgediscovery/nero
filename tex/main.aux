\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{pnas-new}
\citation{naturebe2023prepare,crothers2023machine,thirunavukarasu2023large}
\citation{CoverKing1978}
\citation{detectgpt_icml2023,detectllm_findings2023}
\citation{GacsTrompVitanyi2001}
\citation{GacsTrompVitanyi2001}
\pgfsyspdfmark {pgfid2}{3411189}{43399592}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\zref@newlabel{mdf@pagelabel-1}{\default{\caption@xref {??}{ on input line 215}}\page{1}\abspage{1}\mdf@pagevalue{1}}
\pgfsyspdfmark {pgfid3}{26609889}{5997650}
\citation{grassberger1989estimating}
\citation{CLx,CL12g}
\citation{CoverKing1978}
\citation{williams2006gaussian}
\citation{CoverKing1978}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Cohorts and average entropy rates\relax }}{2}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab1}{{1}{2}{Cohorts and average entropy rates\relax }{table.caption.1}{}}
\newlabel{eq71}{{2}{2}{}{equation.0.2}{}}
\newlabel{prop1}{{1}{2}{Two-Part Code to Entropy}{prop.1}{}}
\newlabel{sec:experiments}{{}{2}{}{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {NERO\xspace  \ performance.} \textbf  {a}, Pooled human-AI ROC curves for training-free NERO\xspace  (median entropy-rate estimate $\hat  H$), and with a Gaussian-process classifier alongside baselines (perplexity from \textsc  {HowGPT} and \textsc  {ZeroGPT} scoring, See Supplementary Methods). \textbf  {b}, Cross-cohort robustness across 381 out-of-sample discrimination tasks obtained by varying the human reference set (Gutenberg, arXiv, or both) and the subset of LLM generators. \textbf  {c}, Mean entropy rates plotted at model release dates (“birthtime”), illustrating upward drift toward the human regime; a weighted Richards fit with a fixed ceiling at the mean human rate is overlaid for descriptive smoothing. \textbf  {d}, Entropy-rate estimates versus document length under truncation (using Gutenberg texts for humans), indicating a practical lower bound for reliable discrimination at shorter lengths around $5,000$ characters. \textbf  {e}, Genre-stratified NERO\xspace  entropy rates for human prose; error bars denote 95\% intervals. \relax }}{2}{figure.caption.2}\protected@file@percent }
\newlabel{figperf}{{1}{2}{\textbf {\NERO \ performance.} \textbf {a}, Pooled human-AI ROC curves for training-free \NERO (median entropy-rate estimate $\hat H$), and with a Gaussian-process classifier alongside baselines (perplexity from \textsc {HowGPT} and \textsc {ZeroGPT} scoring, See Supplementary Methods). \textbf {b}, Cross-cohort robustness across 381 out-of-sample discrimination tasks obtained by varying the human reference set (Gutenberg, arXiv, or both) and the subset of LLM generators. \textbf {c}, Mean entropy rates plotted at model release dates (“birthtime”), illustrating upward drift toward the human regime; a weighted Richards fit with a fixed ceiling at the mean human rate is overlaid for descriptive smoothing. \textbf {d}, Entropy-rate estimates versus document length under truncation (using Gutenberg texts for humans), indicating a practical lower bound for reliable discrimination at shorter lengths around $5,000$ characters. \textbf {e}, Genre-stratified \NERO entropy rates for human prose; error bars denote 95\% intervals. \relax }{figure.caption.2}{}}
\citation{openai_gpt4_architecture}
\citation{Levin1974}
\citation{LiVitanyi2008}
\citation{Chaitin1975}
\bibdata{BibLib1,tom}
\bibcite{naturebe2023prepare}{{1}{}{{}}{{}}}
\bibcite{crothers2023machine}{{2}{}{{}}{{}}}
\bibcite{thirunavukarasu2023large}{{3}{}{{}}{{}}}
\bibcite{CoverKing1978}{{4}{}{{}}{{}}}
\bibcite{detectgpt_icml2023}{{5}{}{{}}{{}}}
\bibcite{detectllm_findings2023}{{6}{}{{}}{{}}}
\bibcite{GacsTrompVitanyi2001}{{7}{}{{}}{{}}}
\bibcite{grassberger1989estimating}{{8}{}{{}}{{}}}
\bibcite{CLx}{{9}{}{{}}{{}}}
\bibcite{CL12g}{{10}{}{{}}{{}}}
\bibcite{williams2006gaussian}{{11}{}{{}}{{}}}
\bibcite{openai_gpt4_architecture}{{12}{}{{}}{{}}}
\bibcite{Levin1974}{{13}{}{{}}{{}}}
\bibcite{LiVitanyi2008}{{14}{}{{}}{{}}}
\bibcite{Chaitin1975}{{15}{}{{}}{{}}}
\bibcite{horibe03}{{16}{}{{}}{{}}}
\@writefile{toc}{\contentsline {matmethods@section}{\numberline {1}Materials and Methods}{3}{matmethods@section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Data acquisition.}{3}{matmethods@section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Code availability.}{3}{matmethods@section.1}\protected@file@percent }
\newlabel{LastPage}{{1}{3}{Materials and Methods}{matmethods@section.1}{}}
\@input{SIpnas.aux}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\newlabel{LastPage}{{}{6}{}{page.6}{}}
\xdef\lastpage@lastpage{6}
\xdef\lastpage@lastpageHy{6}
\gdef \@abspage@last{6}
